{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e134a6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-20T06:38:41.646816Z",
     "iopub.status.busy": "2025-11-20T06:38:41.646093Z",
     "iopub.status.idle": "2025-11-20T06:38:58.746674Z",
     "shell.execute_reply": "2025-11-20T06:38:58.745756Z"
    },
    "papermill": {
     "duration": 17.107537,
     "end_time": "2025-11-20T06:38:58.748516",
     "exception": false,
     "start_time": "2025-11-20T06:38:41.640979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9656796e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:38:58.755900Z",
     "iopub.status.busy": "2025-11-20T06:38:58.755606Z",
     "iopub.status.idle": "2025-11-20T06:38:58.847576Z",
     "shell.execute_reply": "2025-11-20T06:38:58.846685Z"
    },
    "papermill": {
     "duration": 0.097059,
     "end_time": "2025-11-20T06:38:58.848880",
     "exception": false,
     "start_time": "2025-11-20T06:38:58.751821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"/kaggle/input/malimg-original/malimg_paper_dataset_imgs\"\n",
    "BATCH_SIZE = 16  \n",
    "IMG_SIZE = 224   # DeiT menggunakan 224x224\n",
    "NUM_CLASSES = 25\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 5e-5  # Learning rate lebih kecil untuk ViT\n",
    "OUTPUT_DIR = \"/kaggle/working/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5885d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:38:58.855729Z",
     "iopub.status.busy": "2025-11-20T06:38:58.855467Z",
     "iopub.status.idle": "2025-11-20T06:40:00.365830Z",
     "shell.execute_reply": "2025-11-20T06:40:00.364797Z"
    },
    "papermill": {
     "duration": 61.517226,
     "end_time": "2025-11-20T06:40:00.369100",
     "exception": false,
     "start_time": "2025-11-20T06:38:58.851874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mean: 0.4455, std: 0.1723\n"
     ]
    }
   ],
   "source": [
    "temp_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "temp_dataset = datasets.ImageFolder(root=DATA_DIR, transform=temp_transform)\n",
    "loader = DataLoader(temp_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "total_samples = 0\n",
    "for data, _ in loader:\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    total_samples += batch_samples\n",
    "mean /= total_samples\n",
    "std /= total_samples\n",
    "\n",
    "print(f\"Dataset mean: {mean.item():.4f}, std: {std.item():.4f}\")\n",
    "\n",
    "# Data Augmentation untuk training (konsisten dengan SwinV2)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((int(IMG_SIZE * 1.1), int(IMG_SIZE * 1.1))),\n",
    "    transforms.RandomResizedCrop(size=(IMG_SIZE, IMG_SIZE), scale=(0.95, 1.0), ratio=(0.95, 1.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.3),\n",
    "    transforms.RandomApply([\n",
    "        transforms.Lambda(lambda x: torch.clamp(x + torch.randn_like(x) * 0.01, 0, 1))\n",
    "    ], p=0.3),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5b8d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:40:00.376644Z",
     "iopub.status.busy": "2025-11-20T06:40:00.376360Z",
     "iopub.status.idle": "2025-11-20T06:40:01.700034Z",
     "shell.execute_reply": "2025-11-20T06:40:01.699433Z"
    },
    "papermill": {
     "duration": 1.329074,
     "end_time": "2025-11-20T06:40:01.701461",
     "exception": false,
     "start_time": "2025-11-20T06:40:00.372387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_dataset = datasets.ImageFolder(root=DATA_DIR)\n",
    "all_targets = [label for _, label in raw_dataset.samples]\n",
    "all_indices = list(range(len(raw_dataset)))\n",
    "\n",
    "split_path = os.path.join(OUTPUT_DIR, \"train_test_split.npz\")\n",
    "if os.path.exists(split_path):\n",
    "    splits = np.load(split_path)\n",
    "    train_idx, test_idx = splits['train_idx'], splits['test_idx']\n",
    "else:\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        all_indices,\n",
    "        test_size=0.2,\n",
    "        stratify=all_targets,\n",
    "        random_state=42\n",
    "    )\n",
    "    np.savez(split_path, train_idx=train_idx, test_idx=test_idx)\n",
    "\n",
    "train_dataset_raw = datasets.ImageFolder(root=DATA_DIR, transform=train_transform)\n",
    "test_dataset_raw = datasets.ImageFolder(root=DATA_DIR, transform=test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset_raw, train_idx)\n",
    "test_dataset = Subset(test_dataset_raw, test_idx)\n",
    "\n",
    "# Weighted sampling untuk handle class imbalance\n",
    "train_targets = [all_targets[i] for i in train_idx]\n",
    "class_counts = Counter(train_targets)\n",
    "weights = [1.0 / class_counts[train_targets[i]] for i in range(len(train_targets))]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "class_names = raw_dataset.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213bdef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:40:01.708665Z",
     "iopub.status.busy": "2025-11-20T06:40:01.708425Z",
     "iopub.status.idle": "2025-11-20T06:40:04.319532Z",
     "shell.execute_reply": "2025-11-20T06:40:04.318603Z"
    },
    "papermill": {
     "duration": 2.616329,
     "end_time": "2025-11-20T06:40:04.320952",
     "exception": false,
     "start_time": "2025-11-20T06:40:01.704623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411e47f2098e417591c1c8186afbdd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DeiT Small\n",
      "Input size: 224x224\n",
      "Patch size: 16x16\n",
      "Number of classes: 25\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('deit_small_patch16_224', pretrained=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Modifikasi patch embedding untuk 1 channel (grayscale)\n",
    "original_conv = model.patch_embed.proj\n",
    "model.patch_embed.proj = nn.Conv2d(\n",
    "    in_channels=1,  # Grayscale input\n",
    "    out_channels=original_conv.out_channels,\n",
    "    kernel_size=original_conv.kernel_size,\n",
    "    stride=original_conv.stride,\n",
    "    padding=original_conv.padding,\n",
    "    bias=original_conv.bias is not None\n",
    ")\n",
    "\n",
    "# Initialize weights dengan averaging pretrained RGB weights\n",
    "with torch.no_grad():\n",
    "    # Average RGB channels ke single grayscale channel\n",
    "    model.patch_embed.proj.weight[:, 0, :, :] = original_conv.weight.mean(dim=1)\n",
    "    if model.patch_embed.proj.bias is not None:\n",
    "        model.patch_embed.proj.bias.copy_(original_conv.bias)\n",
    "\n",
    "# Modifikasi head dengan dropout\n",
    "model.head = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(model.head.in_features, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Model: DeiT Small\")\n",
    "print(f\"Input size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Patch size: 16x16\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c90f2c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:40:04.328810Z",
     "iopub.status.busy": "2025-11-20T06:40:04.328572Z",
     "iopub.status.idle": "2025-11-20T06:40:04.340791Z",
     "shell.execute_reply": "2025-11-20T06:40:04.339858Z"
    },
    "papermill": {
     "duration": 0.017562,
     "end_time": "2025-11-20T06:40:04.341931",
     "exception": false,
     "start_time": "2025-11-20T06:40:04.324369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Pastikan inputs adalah 2D [batch_size, num_classes]\n",
    "        if inputs.dim() > 2:\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "        \n",
    "        # Pastikan targets adalah 1D tensor dengan tipe long\n",
    "        targets = targets.view(-1).long()\n",
    "        \n",
    "        # Validasi\n",
    "        num_classes = inputs.size(1)\n",
    "        assert targets.min() >= 0, f\"Target min value {targets.min()} is negative\"\n",
    "        assert targets.max() < num_classes, f\"Target max value {targets.max()} >= num_classes {num_classes}\"\n",
    "        \n",
    "        # Hitung cross entropy dengan log softmax\n",
    "        log_probs = torch.nn.functional.log_softmax(inputs, dim=-1)\n",
    "        \n",
    "        # Gunakan nll_loss untuk lebih aman\n",
    "        ce_loss = torch.nn.functional.nll_loss(log_probs, targets, reduction='none')\n",
    "        \n",
    "        # Hitung probability untuk focal weight\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Hitung focal loss\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        # Apply alpha if specified\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_t = self.alpha\n",
    "            else:\n",
    "                alpha_t = self.alpha.gather(0, targets)\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "criterion = FocalLoss(gamma=2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.05)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772be412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:40:04.349316Z",
     "iopub.status.busy": "2025-11-20T06:40:04.349053Z",
     "iopub.status.idle": "2025-11-20T07:07:40.183203Z",
     "shell.execute_reply": "2025-11-20T07:07:40.181947Z"
    },
    "papermill": {
     "duration": 1655.839818,
     "end_time": "2025-11-20T07:07:40.184804",
     "exception": false,
     "start_time": "2025-11-20T06:40:04.344986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDASI DATA\n",
      "============================================================\n",
      "Number of classes: 25\n",
      "Train samples: 7471\n",
      "Test samples: 1868\n",
      "\n",
      "Testing forward pass...\n",
      "Input shape: torch.Size([16, 1, 224, 224])\n",
      "Output shape: torch.Size([16, 25])\n",
      "Expected output shape: [16, 25]\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Epoch 1/20 - Train Loss: 0.2550, Train Acc: 86.19%, Val Loss: 0.0460, Val Acc: 89.94%\n",
      "Epoch 2/20 - Train Loss: 0.0547, Train Acc: 93.67%, Val Loss: 0.0248, Val Acc: 98.07%\n",
      "Epoch 3/20 - Train Loss: 0.0409, Train Acc: 95.02%, Val Loss: 0.0680, Val Acc: 90.10%\n",
      "Epoch 4/20 - Train Loss: 0.0315, Train Acc: 96.29%, Val Loss: 0.0159, Val Acc: 99.14%\n",
      "Epoch 5/20 - Train Loss: 0.0250, Train Acc: 97.48%, Val Loss: 0.0127, Val Acc: 99.30%\n",
      "Epoch 6/20 - Train Loss: 0.0183, Train Acc: 98.42%, Val Loss: 0.0167, Val Acc: 99.14%\n",
      "Epoch 7/20 - Train Loss: 0.0181, Train Acc: 98.23%, Val Loss: 0.0167, Val Acc: 99.09%\n",
      "Epoch 8/20 - Train Loss: 0.0124, Train Acc: 98.47%, Val Loss: 0.0126, Val Acc: 99.52%\n",
      "Epoch 9/20 - Train Loss: 0.0172, Train Acc: 98.34%, Val Loss: 0.0175, Val Acc: 99.36%\n",
      "Epoch 10/20 - Train Loss: 0.0144, Train Acc: 98.47%, Val Loss: 0.0147, Val Acc: 99.25%\n",
      "Epoch 11/20 - Train Loss: 0.0088, Train Acc: 98.85%, Val Loss: 0.0171, Val Acc: 99.41%\n",
      "Epoch 12/20 - Train Loss: 0.0194, Train Acc: 98.69%, Val Loss: 0.0199, Val Acc: 98.93%\n",
      "Epoch 13/20 - Train Loss: 0.0071, Train Acc: 98.98%, Val Loss: 0.0137, Val Acc: 99.41%\n",
      "Epoch 14/20 - Train Loss: 0.0041, Train Acc: 99.26%, Val Loss: 0.0103, Val Acc: 99.46%\n",
      "Epoch 15/20 - Train Loss: 0.0061, Train Acc: 99.04%, Val Loss: 0.0091, Val Acc: 99.41%\n",
      "Epoch 16/20 - Train Loss: 0.0043, Train Acc: 99.22%, Val Loss: 0.0114, Val Acc: 99.46%\n",
      "Epoch 17/20 - Train Loss: 0.0041, Train Acc: 99.30%, Val Loss: 0.0082, Val Acc: 99.46%\n",
      "Epoch 18/20 - Train Loss: 0.0044, Train Acc: 99.32%, Val Loss: 0.0087, Val Acc: 99.57%\n",
      "Epoch 19/20 - Train Loss: 0.0052, Train Acc: 99.13%, Val Loss: 0.0247, Val Acc: 98.98%\n",
      "Epoch 20/20 - Train Loss: 0.0045, Train Acc: 99.33%, Val Loss: 0.0091, Val Acc: 99.57%\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "RESULTS SUMMARY\n",
      "============================================================\n",
      "Test Accuracy: 99.57%\n",
      "Best Val Accuracy: 99.57%\n",
      "Macro Precision: 0.9892\n",
      "Macro Recall: 0.9897\n",
      "Macro F1-Score: 0.9888\n",
      "Total Parameters: 21,478,681\n",
      "Model Size: 81.93 MB\n",
      "Avg Inference Time: 0.53 ms/image\n",
      "Throughput: 1889.17 images/sec\n",
      "\n",
      " DeiT training complete! All results saved to /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDASI DATA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(train_loader))\n",
    "    test_input, test_label = test_batch[0].to(DEVICE), test_batch[1].to(DEVICE)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"Input shape: {test_input.shape}\")\n",
    "    print(f\"Output shape: {test_output.shape}\")\n",
    "    print(f\"Expected output shape: [{test_input.size(0)}, {NUM_CLASSES}]\")\n",
    "    \n",
    "    if test_output.dim() > 2:\n",
    "        print(f\"Output has {test_output.dim()} dimensions, will reshape during training\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Reshape jika diperlukan\n",
    "        if outputs.dim() > 2:\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping untuk stabilitas\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Reshape jika diperlukan\n",
    "            if outputs.dim() > 2:\n",
    "                outputs = outputs.view(outputs.size(0), -1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    val_loss_avg = val_loss / len(test_loader)\n",
    "    val_losses.append(val_loss_avg)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss_avg)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"deit_malimg_best.pth\"))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"deit_malimg_final.pth\"))\n",
    "\n",
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"deit_malimg_best.pth\")))\n",
    "\n",
    "# Evaluasi\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels, inference_times = [], [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        start = time.time()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Reshape jika diperlukan\n",
    "        if outputs.dim() > 2:\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "        \n",
    "        end = time.time()\n",
    "        inference_times.append(end - start)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Metrik\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, average=None, labels=range(NUM_CLASSES), zero_division=0\n",
    ")\n",
    "precision_avg = np.mean(precision)\n",
    "recall_avg = np.mean(recall)\n",
    "f1_avg = np.mean(f1)\n",
    "\n",
    "# Per-class metrics\n",
    "report_df = pd.DataFrame({\n",
    "    'class': class_names,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1-score': f1,\n",
    "    'support': support\n",
    "})\n",
    "report_df.to_csv(os.path.join(OUTPUT_DIR, \"DeiT_per_class_metrics.csv\"), index=False)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "pd.DataFrame(cm, index=class_names, columns=class_names).to_csv(os.path.join(OUTPUT_DIR, \"DeiT_confusion_matrix.csv\"))\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=False, xticklabels=class_names, yticklabels=class_names, cmap='Blues', fmt='d')\n",
    "plt.title(\"Confusion Matrix - DeiT (224x224)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"DeiT_confusion_matrix.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(val_losses, label='Val Loss', marker='s')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Acc', marker='o')\n",
    "plt.plot(val_accuracies, label='Val Acc', marker='s')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"DeiT_training_curves.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Model statistics\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_size_mb = total_params * 4 / (1024 ** 2)\n",
    "avg_time_per_image = np.mean(inference_times) / BATCH_SIZE\n",
    "total_inference_time = sum(inference_times)\n",
    "throughput = len(test_dataset) / total_inference_time\n",
    "\n",
    "summary = {\n",
    "    \"Model\": \"DeiT Small (224x224, 1-Channel, Focal Loss)\",\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Macro Precision\": precision_avg,\n",
    "    \"Macro Recall\": recall_avg,\n",
    "    \"Macro F1\": f1_avg,\n",
    "    \"Best Val Accuracy\": best_val_acc,\n",
    "    \"Total Params\": total_params,\n",
    "    \"Trainable Params\": trainable_params,\n",
    "    \"Model Size (MB)\": model_size_mb,\n",
    "    \"Avg Inference Time (ms)\": avg_time_per_image * 1000,\n",
    "    \"Throughput (img/sec)\": throughput,\n",
    "    \"Hardware\": str(DEVICE) + (f\" ({torch.cuda.get_device_name(0)})\" if torch.cuda.is_available() else \"\")\n",
    "}\n",
    "pd.DataFrame([summary]).to_csv(os.path.join(OUTPUT_DIR, \"DeiT_summary.csv\"), index=False)\n",
    "\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Macro Precision: {precision_avg:.4f}\")\n",
    "print(f\"Macro Recall: {recall_avg:.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_avg:.4f}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Avg Inference Time: {avg_time_per_image*1000:.2f} ms/image\")\n",
    "print(f\"Throughput: {throughput:.2f} images/sec\")\n",
    "print(\"\\n DeiT training complete! All results saved to /kaggle/working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57067ecc",
   "metadata": {
    "papermill": {
     "duration": 0.003938,
     "end_time": "2025-11-20T07:07:40.193166",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.189228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682c3a0",
   "metadata": {
    "papermill": {
     "duration": 0.00377,
     "end_time": "2025-11-20T07:07:40.200863",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.197093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87babb79",
   "metadata": {
    "papermill": {
     "duration": 0.004579,
     "end_time": "2025-11-20T07:07:40.209378",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.204799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399dfdc",
   "metadata": {
    "papermill": {
     "duration": 0.003929,
     "end_time": "2025-11-20T07:07:40.217228",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.213299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1281288",
   "metadata": {
    "papermill": {
     "duration": 0.004145,
     "end_time": "2025-11-20T07:07:40.225278",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.221133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae703a1e",
   "metadata": {
    "papermill": {
     "duration": 0.004055,
     "end_time": "2025-11-20T07:07:40.233402",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.229347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff829f",
   "metadata": {
    "papermill": {
     "duration": 0.004116,
     "end_time": "2025-11-20T07:07:40.241413",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.237297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403be4ed",
   "metadata": {
    "papermill": {
     "duration": 0.003902,
     "end_time": "2025-11-20T07:07:40.249376",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.245474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93141026",
   "metadata": {
    "papermill": {
     "duration": 0.004094,
     "end_time": "2025-11-20T07:07:40.257424",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.253330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72dad3",
   "metadata": {
    "papermill": {
     "duration": 0.004149,
     "end_time": "2025-11-20T07:07:40.265646",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.261497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce5df8",
   "metadata": {
    "papermill": {
     "duration": 0.004013,
     "end_time": "2025-11-20T07:07:40.273545",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.269532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f683ae7",
   "metadata": {
    "papermill": {
     "duration": 0.003912,
     "end_time": "2025-11-20T07:07:40.281309",
     "exception": false,
     "start_time": "2025-11-20T07:07:40.277397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2002344,
     "sourceId": 3310783,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1745.76387,
   "end_time": "2025-11-20T07:07:43.347586",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T06:38:37.583716",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1df66e805aca43f3bad157a90bd2be5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_505c7d32295a4017875c87fba6cab183",
       "max": 88216496.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a3ab69cde36e4c0eb5e9f8462fc3c64c",
       "tabbable": null,
       "tooltip": null,
       "value": 88216496.0
      }
     },
     "3912ddd1da644cd2b03153ebe7f1d482": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39cb04722b614da588517b0aba9ed1e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "411e47f2098e417591c1c8186afbdd1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6daeed7853f540caa703ab33fa87869a",
        "IPY_MODEL_1df66e805aca43f3bad157a90bd2be5a",
        "IPY_MODEL_b50f1c0ef1b44dd98b5465872ff6e37f"
       ],
       "layout": "IPY_MODEL_d97e7dc3ca024e1a8080ff094ee1e7a3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "47cee234dfa044c294bc807e0391fa46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "505c7d32295a4017875c87fba6cab183": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "589540dfeae94aa1b63cbfecaba9c378": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6daeed7853f540caa703ab33fa87869a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3912ddd1da644cd2b03153ebe7f1d482",
       "placeholder": "​",
       "style": "IPY_MODEL_589540dfeae94aa1b63cbfecaba9c378",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "a3ab69cde36e4c0eb5e9f8462fc3c64c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b50f1c0ef1b44dd98b5465872ff6e37f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_47cee234dfa044c294bc807e0391fa46",
       "placeholder": "​",
       "style": "IPY_MODEL_39cb04722b614da588517b0aba9ed1e8",
       "tabbable": null,
       "tooltip": null,
       "value": " 88.2M/88.2M [00:01&lt;00:00, 67.9MB/s]"
      }
     },
     "d97e7dc3ca024e1a8080ff094ee1e7a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
